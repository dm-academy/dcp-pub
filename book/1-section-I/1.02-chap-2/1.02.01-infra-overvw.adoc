==== Infrastructure overview

In the previous chapter, you were introduced to the concept of a Moment of Truth, and in the final exercises asked to think of a product idea. Some part of that product requires writing software, or at least configuring some IT-centric system. (IT being defined as in Chapter 1.)

****
NOTE: Moment of Truth & Minimum Viable Product

A Minimum Viable Product is required to deliver an initial Moment of Truth. You need infrastructure capable of supporting your Minimum Viable Product's idea.
****

You presumably have some resources (time and money). It’s Monday morning, you have cleared all distractions, shut down your Twitter and Facebook feeds, and are ready to start building.

Not so fast.

Before you can start writing code, you need some kind of a platform. It's hard to build before you decide on your tools.

You need to decide what language you are going to write in, or what framework you are going to configure, and how that effort is going to result in an operational system capable of rendering IT services.

You are probably swimming in a sea of advice and options regarding your technical choices. In previous decades, books such as this might have gone into the specifics of particular platforms: mainframe vs. minicomputers, COBOL vs Fortran, Windows vs Unix, etc.

At this writing, JavaScript is a leading choice, in conjunction with various frameworks and NoSQL options (e.g. the MEAN stack, for MongoDB, Express, Angular, and Node.js), but millions of developers are still writing Java and .Net, and Ruby and Python have significant followings. Linux is arguably the leading platform, but commercial Unix and Microsoft platforms are still strong. And, periodically it's reported that the majority of the world's transactions *still* run on http://blog.hackerrank.com/the-inevitable-return-of-cobol/[COBOL-based systems].

However, in the past few years, some powerful infrastructure concepts have solidified that are independent of particular platforms:

* Automation and “infrastructure as code”
* The centrality of source control
* The importance of package management
* Policy-based infrastructure management

(We'll get to test-driven development & DevOps in the next chapter.)

This might seem like a detour - you are in a hurry to start writing code! But industry practice is clear. You check your code into source control from Day One. You define your server configurations as recipes, manifests, or at least shell scripts, and check those definitions into source control as well. You keep track of what you have downloaded from the Internet and what version of stuff you are using. Always downloading the “latest” package from its upstream creator might seem like the way to stay current, but it will kill you when stuff works on one server but not on another.

So, you need to understand a few things and make a few decisions that you will be living with for a while, and will not be easily changed.

===== What is Infrastructure?

Infrastructure is a tricky word. Google defines it thus:

￼_The basic physical and organizational structures and facilities (e.g., buildings, roads, and power supplies) needed for the operation of a society or enterprise._

In general, it connotes the stuff behind the scenes, the things you need but don’t want to spend a lot of time thinking about.

We will spend a lot of time examining what we mean by “infrastructure” in this book, as it is fundamental to understanding the “business of IT.”

This book defines “IT infrastructure” recursively as “the set of IT concerns that are of particular interest to IT.”

* An application or business service is consumed by people who are NOT primarily concerned with IT. For example, a customer-facing online banking service is consumed by end users.

* An IT infrastructure service is a service consumed by other IT-centric teams and capabilities. For example, a database or a load balancing service is consumed by other IT teams.

IT infrastructure is one form of infrastructure. Other kinds of infrastructure might include mechanical, electrical, and plant investments (ME & P). IT infrastructure, like IT itself, is defined by its fundamental dependence on information and computing theory [link Chapter 1].

The interesting thing is that today’s application becomes tomorrow’s infrastructure. Forty years ago, building an “application” would have included building its database, perhaps even its file management. This was rightly determined to be a general-case problem that could be the basis for commodity software, and so companies like Oracle were born.

Operating systems took on more and more functionality, technology became more and more reliable and easily configured, and once unique (and competitively differentiating) functionality became commoditized and more and more deeply buried in the “stack”: the IT infrastructure.

===== Basic IT infrastructure concepts

There are many books (some in the Further Reading section for this chapter) on all aspects of IT infrastructure, which is a broad and deep topic. Our discussion of it here has to be high level, as appropriate for a survey course.

We've established http://dm-academy.github.io/aitm/#_defining_information_technology[what we mean by IT generally]. Pragmatically, there are three major physical aspects to "IT infrastructure" relevant to the practitioner:

* Computing cycles (sometimes called just "compute")
* Memory & storage (or "storage")
* Networking & communications (or "network")

Those are the fundamentals. We will discuss a wide variety of subsidiary concerns and concepts, but those are the big three.

*Compute* is the resource that performs the rapid, clock-driven digital logic that transforms data inputs to outputs.

TIP: For a beginner-level introduction to the world of digital logic at its most fundamental, see  http://www.goodreads.com/book/show/44882.Code[_Code_], by Charles Petzold.

If we have a picture of our friend, and we use a digital filter to adjust the brightness, that is an application of compute power. The picture is made up of "pixels" which are nothing but numbers representing the color of some tiny square of the picture. Each of those numbers needs to be evaluated and the brightness adjusted.

For example, let's say that the pixel values range from 1 to 10, with 1 being the darkest and 10 being the lightest (in reality, the range is much larger.) We might tell the computer:

. Look at a pixel
. If it is between 0 and 3 add 2
. If it is between 4 and 6 add 1
. Repeat until all pixels are done

At a more realistic level, the process might be executed as a batch on a workstation, for hundreds or thousands of photos at a time.

Computers process instructions at the level of "true" and "false," represented as https://en.wikipedia.org/wiki/Binary_number[binary] "1s" and "0s." Because humans cannot easily understand binary data and processing, higher-level abstractions of https://en.wikipedia.org/wiki/Machine_code[machine code] and https://en.wikipedia.org/wiki/Programming_language[programming languages] are used.

IMPORTANT: If these concepts are strange to you, spend some time with the suggested Wikipedia articles, or otherwise researching the topics. Wikipedia in the area of fundamental computer concepts is generally accurate.

*Storage* But where did the picture come from? The data comprising the pixels needs to be stored somewhere. Sometimes you will hear the technical term "persisted." The combined set of pixels and their precise values can be termed the "state" of the photograph; the filter alters the state, and also needs to save this new state somewhere (otherwise it will be lost).

Many technologies http://www.zetta.net/history-of-computer-storage/[have been used for digital storage.] Increasingly, the IT professional need not be concerned with the physical infrastructure used for storing data. As we will cover in the next section, storage increasingly is experienced as a virtual resource, accessed through executing programmed logic on Cloud platforms. "Underneath the covers" the Cloud provider might be using various forms of storage, from RAM to solid state drives to tapes, but the end user is shielded from the implementation details (part of the definition of a service).

However, it is important to understand that in general, storage follows a hierarchy. Just as we might "store" a document by holding it in our hands, setting it on a desktop, filing it in a cabinet, or archiving it in a banker's box in an offsite warehouse, so computer storage also has different levels of speed and accessibility.

Cache is on the same chip as the processor.
